{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from convnet import SimpleConvNet\n",
    "from convnet_trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2999977259488857\n",
      "=== epoch:1, train acc:0.22, test acc:0.212 ===\n",
      "train loss:2.2989991981338167\n",
      "train loss:2.2954566792439643\n",
      "train loss:2.2871204556851485\n",
      "train loss:2.2851175029596957\n",
      "train loss:2.270605192754541\n",
      "train loss:2.2577800437976983\n",
      "train loss:2.2348703074191105\n",
      "train loss:2.236732987458903\n",
      "train loss:2.2115870427314084\n",
      "train loss:2.184208621637181\n",
      "train loss:2.136938590429979\n",
      "train loss:2.101799816653036\n",
      "train loss:2.0802996319560787\n",
      "train loss:1.9976100783003028\n",
      "train loss:1.9552604231018618\n",
      "train loss:1.9546377984706929\n",
      "train loss:1.8234550045466764\n",
      "train loss:1.833099988841002\n",
      "train loss:1.7278740774479666\n",
      "train loss:1.6873586150941542\n",
      "train loss:1.5743264584211942\n",
      "train loss:1.552060451300474\n",
      "train loss:1.3595616465140126\n",
      "train loss:1.2580037633410572\n",
      "train loss:1.1912000994803111\n",
      "train loss:1.2424448889803625\n",
      "train loss:0.9992531758280908\n",
      "train loss:1.0918600061178534\n",
      "train loss:0.9880124751951535\n",
      "train loss:1.057800580456656\n",
      "train loss:0.938636913863024\n",
      "train loss:0.8386813136702856\n",
      "train loss:0.8490921470124381\n",
      "train loss:0.8266418098042084\n",
      "train loss:0.6939079318963008\n",
      "train loss:0.6768902009849879\n",
      "train loss:0.6367635435887503\n",
      "train loss:0.6130628923686318\n",
      "train loss:0.6760754051760318\n",
      "train loss:0.6582174583081936\n",
      "train loss:0.6082346293651786\n",
      "train loss:0.45582144155207344\n",
      "train loss:0.5919580842350209\n",
      "train loss:0.43067516654367277\n",
      "train loss:0.36033982166477085\n",
      "train loss:0.5022544885457996\n",
      "train loss:0.5896850094121824\n",
      "train loss:0.6123060298503173\n",
      "train loss:0.42108535182903745\n",
      "train loss:0.4001832757387435\n",
      "=== epoch:2, train acc:0.823, test acc:0.814 ===\n",
      "train loss:0.4676749639648971\n",
      "train loss:0.41359618783807667\n",
      "train loss:0.5114261353792784\n",
      "train loss:0.4925381185495027\n",
      "train loss:0.557642623577446\n",
      "train loss:0.43625963709127374\n",
      "train loss:0.515460753560606\n",
      "train loss:0.3312377673271025\n",
      "train loss:0.5117115070245619\n",
      "train loss:0.41446558522960936\n",
      "train loss:0.441647381424205\n",
      "train loss:0.43296439780613705\n",
      "train loss:0.5168083367198056\n",
      "train loss:0.41030766000663305\n",
      "train loss:0.3820990079869781\n",
      "train loss:0.4496168042485773\n",
      "train loss:0.6247047490482658\n",
      "train loss:0.4323432348652903\n",
      "train loss:0.7953118952263454\n",
      "train loss:0.4184825811253172\n",
      "train loss:0.40674834134537713\n",
      "train loss:0.38277088854495717\n",
      "train loss:0.4896709528383814\n",
      "train loss:0.43197454108283134\n",
      "train loss:0.26092507062262366\n",
      "train loss:0.32696078322952254\n",
      "train loss:0.28050130542219154\n",
      "train loss:0.3897279930894524\n",
      "train loss:0.5504891781236495\n",
      "train loss:0.2665727023686699\n",
      "train loss:0.4263500985174946\n",
      "train loss:0.39821018399368036\n",
      "train loss:0.3223928225878395\n",
      "train loss:0.48898307996448565\n",
      "train loss:0.39955678275861195\n",
      "train loss:0.2975202821986917\n",
      "train loss:0.2813926244871556\n",
      "train loss:0.4600694845943142\n",
      "train loss:0.36333407208988056\n",
      "train loss:0.28641842248428395\n",
      "train loss:0.3157162969910883\n",
      "train loss:0.3707252609659374\n",
      "train loss:0.38928623551536495\n",
      "train loss:0.27356484938260617\n",
      "train loss:0.2551323638426564\n",
      "train loss:0.3621262817693988\n",
      "train loss:0.28692104447777916\n",
      "train loss:0.366898243004041\n",
      "train loss:0.29501539342668726\n",
      "train loss:0.35559501590661674\n",
      "=== epoch:3, train acc:0.867, test acc:0.869 ===\n",
      "train loss:0.3419123204258922\n",
      "train loss:0.36628624409713595\n",
      "train loss:0.2616560622569462\n",
      "train loss:0.3093437442795801\n",
      "train loss:0.33717899146273295\n",
      "train loss:0.22967161237822686\n",
      "train loss:0.37281233687440996\n",
      "train loss:0.3782753481183099\n",
      "train loss:0.27938189607538444\n",
      "train loss:0.24179847472160865\n",
      "train loss:0.29546269532539143\n",
      "train loss:0.264291365852161\n",
      "train loss:0.33146193312858196\n",
      "train loss:0.20330475101465562\n",
      "train loss:0.30846522385526404\n",
      "train loss:0.2258945790672853\n",
      "train loss:0.3237661991280784\n",
      "train loss:0.3062121184796918\n",
      "train loss:0.25057633820253467\n",
      "train loss:0.28242203657302173\n",
      "train loss:0.17336716060913898\n",
      "train loss:0.26245711610973754\n",
      "train loss:0.24774242629973064\n",
      "train loss:0.29539424373474754\n",
      "train loss:0.1840353014999609\n",
      "train loss:0.3069074000757133\n",
      "train loss:0.22198054312700044\n",
      "train loss:0.3985180543604083\n",
      "train loss:0.3493766662579818\n",
      "train loss:0.30099624808439557\n",
      "train loss:0.41909968709616174\n",
      "train loss:0.7000432435044962\n",
      "train loss:0.5842770912912639\n",
      "train loss:0.4552749228053159\n",
      "train loss:0.3307740593263674\n",
      "train loss:0.262063266716939\n",
      "train loss:0.16968390997326815\n",
      "train loss:0.47038028210624233\n",
      "train loss:0.294661277844299\n",
      "train loss:0.271651822652001\n",
      "train loss:0.3588439655187057\n",
      "train loss:0.2396730208510557\n",
      "train loss:0.2264973143474197\n",
      "train loss:0.34354586226722167\n",
      "train loss:0.18274862548403156\n",
      "train loss:0.2839147670524779\n",
      "train loss:0.2243795938305184\n",
      "train loss:0.4352416856766326\n",
      "train loss:0.3528925559879857\n",
      "train loss:0.2844283938393715\n",
      "=== epoch:4, train acc:0.894, test acc:0.885 ===\n",
      "train loss:0.22719387942890223\n",
      "train loss:0.180512118232582\n",
      "train loss:0.3957275370158878\n",
      "train loss:0.36180508239914794\n",
      "train loss:0.27865130032017793\n",
      "train loss:0.28777725839214613\n",
      "train loss:0.3604598543849081\n",
      "train loss:0.3062799527069969\n",
      "train loss:0.21588373738031252\n",
      "train loss:0.3348583414022855\n",
      "train loss:0.29870823129464275\n",
      "train loss:0.16499801112347778\n",
      "train loss:0.21444072739469175\n",
      "train loss:0.22422136483510507\n",
      "train loss:0.21809930343740597\n",
      "train loss:0.32169633707276474\n",
      "train loss:0.2968419035076367\n",
      "train loss:0.27929784252691875\n",
      "train loss:0.23122264838969567\n",
      "train loss:0.15738085366532212\n",
      "train loss:0.23587911901462735\n",
      "train loss:0.21636762220623532\n",
      "train loss:0.32594364540433424\n",
      "train loss:0.31460464040375524\n",
      "train loss:0.3193106224477706\n",
      "train loss:0.30454926752261996\n",
      "train loss:0.21454852880715422\n",
      "train loss:0.2128795967192943\n",
      "train loss:0.18650331328014033\n",
      "train loss:0.2192963322123622\n",
      "train loss:0.19478452554568737\n",
      "train loss:0.4176930216340186\n",
      "train loss:0.17791691928170011\n",
      "train loss:0.1409307756442892\n",
      "train loss:0.2600773560917715\n",
      "train loss:0.21458346591062824\n",
      "train loss:0.2476153870844432\n",
      "train loss:0.19549974525300012\n",
      "train loss:0.2533463191390995\n",
      "train loss:0.1881428170674618\n",
      "train loss:0.2778600673344443\n",
      "train loss:0.2973262953569233\n",
      "train loss:0.16867499482559814\n",
      "train loss:0.212185653914782\n",
      "train loss:0.18298048664740998\n",
      "train loss:0.21652206666708776\n",
      "train loss:0.27830317929235354\n",
      "train loss:0.17281425594592736\n",
      "train loss:0.2597056135342457\n",
      "train loss:0.28256849294334674\n",
      "=== epoch:5, train acc:0.918, test acc:0.914 ===\n",
      "train loss:0.30549906817289463\n",
      "train loss:0.20299155494362026\n",
      "train loss:0.1867692498786626\n",
      "train loss:0.349174777925557\n",
      "train loss:0.22379268446831474\n",
      "train loss:0.19179587040020535\n",
      "train loss:0.1985222273872111\n",
      "train loss:0.2858256556473906\n",
      "train loss:0.1947713498609993\n",
      "train loss:0.2907183812444588\n",
      "train loss:0.24131838644985695\n",
      "train loss:0.282031623848604\n",
      "train loss:0.24403646348355376\n",
      "train loss:0.23274067391883665\n",
      "train loss:0.22733669635004872\n",
      "train loss:0.1957385480173028\n",
      "train loss:0.20850546348997448\n",
      "train loss:0.2942100852029084\n",
      "train loss:0.1859725539433879\n",
      "train loss:0.18445980113533103\n",
      "train loss:0.23723803775070085\n",
      "train loss:0.2558705791459906\n",
      "train loss:0.2850500113949633\n",
      "train loss:0.2951049515672856\n",
      "train loss:0.2347460744140128\n",
      "train loss:0.2770113088683728\n",
      "train loss:0.38086891134163764\n",
      "train loss:0.15953631392709192\n",
      "train loss:0.21784333922114624\n",
      "train loss:0.21548375322042104\n",
      "train loss:0.31295797356911725\n",
      "train loss:0.38541649104624187\n",
      "train loss:0.21212926612783534\n",
      "train loss:0.21751581067330583\n",
      "train loss:0.16546239232832918\n",
      "train loss:0.21090022163074404\n",
      "train loss:0.24227948500118554\n",
      "train loss:0.3608281296201591\n",
      "train loss:0.18321248004324403\n",
      "train loss:0.11364970680057064\n",
      "train loss:0.08795841749757427\n",
      "train loss:0.111414921043663\n",
      "train loss:0.24396004039323924\n",
      "train loss:0.16150493226123802\n",
      "train loss:0.17236120675441582\n",
      "train loss:0.17196152101403925\n",
      "train loss:0.20810703595382254\n",
      "train loss:0.13890552870936898\n",
      "train loss:0.2039684700625991\n",
      "train loss:0.19630180452946674\n",
      "=== epoch:6, train acc:0.934, test acc:0.912 ===\n",
      "train loss:0.2904792859329431\n",
      "train loss:0.20783869785325176\n",
      "train loss:0.14225846368442163\n",
      "train loss:0.09997982703823727\n",
      "train loss:0.10947828533267719\n",
      "train loss:0.1887502055576361\n",
      "train loss:0.21938118421185274\n",
      "train loss:0.16919354178236937\n",
      "train loss:0.34113746833994296\n",
      "train loss:0.2042798966744678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.12383609171680825\n",
      "train loss:0.10242152966099351\n",
      "train loss:0.14155831966569868\n",
      "train loss:0.11419427617596224\n",
      "train loss:0.15196053897487222\n",
      "train loss:0.17384549678298067\n",
      "train loss:0.16564859685018185\n",
      "train loss:0.08266618010506468\n",
      "train loss:0.22054129748143161\n",
      "train loss:0.2145039371407246\n",
      "train loss:0.05455170957142948\n",
      "train loss:0.09157678294594485\n",
      "train loss:0.18003506127930385\n",
      "train loss:0.22187817617142602\n",
      "train loss:0.2266702604504008\n",
      "train loss:0.13690073148508303\n",
      "train loss:0.20137547207128706\n",
      "train loss:0.20405045412178852\n",
      "train loss:0.15584579899741763\n",
      "train loss:0.20543182585176045\n",
      "train loss:0.09711963295284748\n",
      "train loss:0.2611359001909749\n",
      "train loss:0.30855851613443286\n",
      "train loss:0.1858421663628984\n",
      "train loss:0.19661110683929656\n",
      "train loss:0.18199355216378238\n",
      "train loss:0.09670306145514748\n",
      "train loss:0.379220599975287\n",
      "train loss:0.16630998362341415\n",
      "train loss:0.2700605705471042\n",
      "train loss:0.14334314083334054\n",
      "train loss:0.2340856245230349\n",
      "train loss:0.13901112003966395\n",
      "train loss:0.1282469146075867\n",
      "train loss:0.15656406292207245\n",
      "train loss:0.08362240921242957\n",
      "train loss:0.12280980129900156\n",
      "train loss:0.14299533906306194\n",
      "train loss:0.2403215831472675\n",
      "train loss:0.15988703485531924\n",
      "=== epoch:7, train acc:0.944, test acc:0.929 ===\n",
      "train loss:0.19203759195840997\n",
      "train loss:0.11605488168710153\n",
      "train loss:0.1294874875593145\n",
      "train loss:0.13240392352702343\n",
      "train loss:0.09119766661581771\n",
      "train loss:0.14041058498226217\n",
      "train loss:0.23126543105278605\n",
      "train loss:0.13686516745954705\n",
      "train loss:0.16701603867079398\n",
      "train loss:0.11147642865664967\n",
      "train loss:0.11877317871881887\n",
      "train loss:0.197728244456326\n",
      "train loss:0.15756574248319224\n",
      "train loss:0.11342054926307497\n",
      "train loss:0.1655158864429445\n",
      "train loss:0.14706824828134427\n",
      "train loss:0.2004643739194731\n",
      "train loss:0.10748251370104855\n",
      "train loss:0.2278616613065753\n",
      "train loss:0.2585753302599076\n",
      "train loss:0.12987553425376733\n",
      "train loss:0.15844449449117465\n",
      "train loss:0.13072145300352594\n",
      "train loss:0.1611735236447146\n",
      "train loss:0.0940147633059366\n",
      "train loss:0.09023328296509225\n",
      "train loss:0.09993435608803714\n",
      "train loss:0.179078656349946\n",
      "train loss:0.16391581373326677\n",
      "train loss:0.1784812367054691\n",
      "train loss:0.10674662771716212\n",
      "train loss:0.1320707393208092\n",
      "train loss:0.07685295527354667\n",
      "train loss:0.1093501307876029\n",
      "train loss:0.10544993773493161\n",
      "train loss:0.1435207084954968\n",
      "train loss:0.1205257244076422\n",
      "train loss:0.18729936059256297\n",
      "train loss:0.1512916091824247\n",
      "train loss:0.1329662230957856\n",
      "train loss:0.10764831272081268\n",
      "train loss:0.16612975207717856\n",
      "train loss:0.1654877958010636\n",
      "train loss:0.2367027544001551\n",
      "train loss:0.09008627402370743\n",
      "train loss:0.12620241431885884\n",
      "train loss:0.0864569989400837\n",
      "train loss:0.1161620194161038\n",
      "train loss:0.11099772145562634\n",
      "train loss:0.12445832916114478\n",
      "=== epoch:8, train acc:0.956, test acc:0.925 ===\n",
      "train loss:0.08073422774650477\n",
      "train loss:0.15630070720014996\n",
      "train loss:0.11726996197280633\n",
      "train loss:0.16447772580778874\n",
      "train loss:0.14564659512237535\n",
      "train loss:0.32432294728077393\n",
      "train loss:0.20165387127807663\n",
      "train loss:0.11218890552722036\n",
      "train loss:0.1539487903434782\n",
      "train loss:0.07129940012339549\n",
      "train loss:0.05924617333943306\n",
      "train loss:0.13917691061387685\n",
      "train loss:0.1387797650822397\n",
      "train loss:0.10348278454867234\n",
      "train loss:0.11159149957259949\n",
      "train loss:0.05647674973912222\n",
      "train loss:0.1463673921342175\n",
      "train loss:0.21190480372537404\n",
      "train loss:0.10011310993662649\n",
      "train loss:0.042816012604245474\n",
      "train loss:0.0934902124147462\n",
      "train loss:0.21360557791508505\n",
      "train loss:0.20941882013964733\n",
      "train loss:0.10202524403019758\n",
      "train loss:0.1626397194964404\n",
      "train loss:0.198406923237832\n",
      "train loss:0.1484199556752037\n",
      "train loss:0.1037164812524682\n",
      "train loss:0.14979089290082948\n",
      "train loss:0.05110370897069586\n",
      "train loss:0.13747246438610827\n",
      "train loss:0.147465493164354\n",
      "train loss:0.14963972717596227\n",
      "train loss:0.09344518735770187\n",
      "train loss:0.09406137449358053\n",
      "train loss:0.1349129350469908\n",
      "train loss:0.08399203868719436\n",
      "train loss:0.12746111478298888\n",
      "train loss:0.1771194582589486\n",
      "train loss:0.07612077106941605\n",
      "train loss:0.1484783113441449\n",
      "train loss:0.16656635061145966\n",
      "train loss:0.055116854898624563\n",
      "train loss:0.1743570528216975\n",
      "train loss:0.0882419598714825\n",
      "train loss:0.08723384381300497\n",
      "train loss:0.10951495158634156\n",
      "train loss:0.14094624716977477\n",
      "train loss:0.11846241989758143\n",
      "train loss:0.09899966887533898\n",
      "=== epoch:9, train acc:0.957, test acc:0.936 ===\n",
      "train loss:0.08984195528735635\n",
      "train loss:0.09172739730329345\n",
      "train loss:0.11940370952549215\n",
      "train loss:0.049951078847057094\n",
      "train loss:0.17570422005387834\n",
      "train loss:0.11668853412470762\n",
      "train loss:0.13462229473852397\n",
      "train loss:0.03805377259073757\n",
      "train loss:0.09624189540062986\n",
      "train loss:0.15460526335707092\n",
      "train loss:0.09583919666771226\n",
      "train loss:0.06829868365695063\n",
      "train loss:0.17246978182792183\n",
      "train loss:0.10876291288882847\n",
      "train loss:0.09885594276897842\n",
      "train loss:0.058093481886820515\n",
      "train loss:0.10144814583099797\n",
      "train loss:0.09312717836703804\n",
      "train loss:0.11211086575190081\n",
      "train loss:0.06252813265907803\n",
      "train loss:0.05530452844352305\n",
      "train loss:0.08436478795186869\n",
      "train loss:0.08238631550083853\n",
      "train loss:0.09109694506227842\n",
      "train loss:0.061139628960840645\n",
      "train loss:0.12361030172137713\n",
      "train loss:0.21675790409223517\n",
      "train loss:0.049333271772110644\n",
      "train loss:0.08244214626515564\n",
      "train loss:0.16636369047971555\n",
      "train loss:0.046057424653829934\n",
      "train loss:0.0777730065733266\n",
      "train loss:0.13810578141034752\n",
      "train loss:0.08781890190168283\n",
      "train loss:0.10091694065726038\n",
      "train loss:0.050015330127800434\n",
      "train loss:0.09278210770757252\n",
      "train loss:0.0991604465155942\n",
      "train loss:0.06280143620697848\n",
      "train loss:0.07944199609705939\n",
      "train loss:0.060017677082743456\n",
      "train loss:0.07854917998795734\n",
      "train loss:0.04882935417533703\n",
      "train loss:0.09145155857487065\n",
      "train loss:0.09231755473712941\n",
      "train loss:0.09177808118729072\n",
      "train loss:0.13776248204521516\n",
      "train loss:0.03186480795929588\n",
      "train loss:0.08074356278988035\n",
      "train loss:0.0828355933248241\n",
      "=== epoch:10, train acc:0.958, test acc:0.94 ===\n",
      "train loss:0.06324404286814722\n",
      "train loss:0.11575756917907937\n",
      "train loss:0.09032180154884052\n",
      "train loss:0.10406513982198069\n",
      "train loss:0.09783865351854092\n",
      "train loss:0.14249736725703607\n",
      "train loss:0.10483516333983528\n",
      "train loss:0.10120255754309992\n",
      "train loss:0.19516064568030342\n",
      "train loss:0.09652287123737238\n",
      "train loss:0.10268020949898124\n",
      "train loss:0.06334651191651493\n",
      "train loss:0.07856537178006764\n",
      "train loss:0.22693680525913787\n",
      "train loss:0.13539426762311127\n",
      "train loss:0.03942994486809391\n",
      "train loss:0.05567870371702885\n",
      "train loss:0.06096387035029235\n",
      "train loss:0.1573420787637893\n",
      "train loss:0.10783871473203727\n",
      "train loss:0.06045270288325253\n",
      "train loss:0.15565605204944988\n",
      "train loss:0.06663730749202663\n",
      "train loss:0.2319026186274421\n",
      "train loss:0.046223503733616535\n",
      "train loss:0.0701272191396071\n",
      "train loss:0.034860326752437436\n",
      "train loss:0.040445501136479364\n",
      "train loss:0.11503339075094793\n",
      "train loss:0.1698040415747522\n",
      "train loss:0.09128972674106901\n",
      "train loss:0.10114326293694581\n",
      "train loss:0.08974937727929387\n",
      "train loss:0.10902707297352268\n",
      "train loss:0.046280355020724605\n",
      "train loss:0.25812296856762185\n",
      "train loss:0.21621626841337693\n",
      "train loss:0.10892674248323901\n",
      "train loss:0.1391139305370289\n",
      "train loss:0.072017480426467\n",
      "train loss:0.15207991137205348\n",
      "train loss:0.08638465666744155\n",
      "train loss:0.1612066496004805\n",
      "train loss:0.10621611763529763\n",
      "train loss:0.09006499224730938\n",
      "train loss:0.04581740897787959\n",
      "train loss:0.15071188171250016\n",
      "train loss:0.0907580917391567\n",
      "train loss:0.08304207282924965\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.947\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnetwork.save_params(\"params.pkl\")\\nprint(\"Saved Network Parameters!\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매개변수 보존\n",
    "\"\"\"\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
