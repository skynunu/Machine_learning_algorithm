{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from convnet import SimpleConvNet\n",
    "from convnet_trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2986278355055685\n",
      "=== epoch:1, train acc:0.16, test acc:0.176 ===\n",
      "train loss:2.2967684921350076\n",
      "train loss:2.292636430251326\n",
      "train loss:2.2857031691187957\n",
      "train loss:2.273042602632095\n",
      "train loss:2.2612208034560872\n",
      "train loss:2.2428201825654908\n",
      "train loss:2.2290089572554814\n",
      "train loss:2.1952328830050947\n",
      "train loss:2.181603028825661\n",
      "train loss:2.1404179724006114\n",
      "train loss:2.0850016739576622\n",
      "train loss:2.0538051886430257\n",
      "train loss:1.984189854188697\n",
      "train loss:1.8951271733319224\n",
      "train loss:1.8636593583836731\n",
      "train loss:1.7139757451598086\n",
      "train loss:1.6765744252357448\n",
      "train loss:1.703875862115708\n",
      "train loss:1.625084651274087\n",
      "train loss:1.4733847711689276\n",
      "train loss:1.4036663101378142\n",
      "train loss:1.2820058629171385\n",
      "train loss:1.2840504022164803\n",
      "train loss:1.1299392642916368\n",
      "train loss:1.2274172299387707\n",
      "train loss:0.9949860279854374\n",
      "train loss:1.0619335479022596\n",
      "train loss:0.8012391662974678\n",
      "train loss:0.8854279259609218\n",
      "train loss:0.8086104425750462\n",
      "train loss:0.7490751296252932\n",
      "train loss:0.785833363910707\n",
      "train loss:0.671515591001742\n",
      "train loss:0.7862964760864354\n",
      "train loss:0.6733937813876775\n",
      "train loss:0.8557349822264682\n",
      "train loss:0.6810543469252711\n",
      "train loss:0.8292926018134342\n",
      "train loss:0.7304106343129901\n",
      "train loss:0.6151678685769099\n",
      "train loss:0.4743619976724068\n",
      "train loss:0.7983992496121732\n",
      "train loss:0.6929662943182062\n",
      "train loss:0.5469493103369568\n",
      "train loss:0.6391885057476854\n",
      "train loss:0.6165756740659026\n",
      "train loss:0.5871674108152013\n",
      "train loss:0.6316341423622726\n",
      "train loss:0.6404534896090365\n",
      "train loss:0.34539207270960604\n",
      "=== epoch:2, train acc:0.818, test acc:0.794 ===\n",
      "train loss:0.6086934388510307\n",
      "train loss:0.6458728077200925\n",
      "train loss:0.5586056953007249\n",
      "train loss:0.3679817246799275\n",
      "train loss:0.57201837085817\n",
      "train loss:0.4103249727347337\n",
      "train loss:0.4276950384147485\n",
      "train loss:0.4321875986316743\n",
      "train loss:0.49214378708580186\n",
      "train loss:0.5457034065289339\n",
      "train loss:0.36487591960739807\n",
      "train loss:0.43092931436956744\n",
      "train loss:0.3378996788662534\n",
      "train loss:0.46505760802434554\n",
      "train loss:0.422623607850161\n",
      "train loss:0.5547639412889902\n",
      "train loss:0.36506575218150744\n",
      "train loss:0.4546006494315915\n",
      "train loss:0.46711577274354404\n",
      "train loss:0.45231074540869814\n",
      "train loss:0.4764430535601524\n",
      "train loss:0.2911850815830819\n",
      "train loss:0.303180170016597\n",
      "train loss:0.5483184084293089\n",
      "train loss:0.2973011405065715\n",
      "train loss:0.3313752463226464\n",
      "train loss:0.46206488577335814\n",
      "train loss:0.433879574879414\n",
      "train loss:0.496557057058975\n",
      "train loss:0.3255459835692275\n",
      "train loss:0.5441566400881702\n",
      "train loss:0.32983978944077\n",
      "train loss:0.3636526053140552\n",
      "train loss:0.23500011181404648\n",
      "train loss:0.24143083003850985\n",
      "train loss:0.2522109672581255\n",
      "train loss:0.2371551289801055\n",
      "train loss:0.4197378637248183\n",
      "train loss:0.2879469782820576\n",
      "train loss:0.4144924908853427\n",
      "train loss:0.3245634416009671\n",
      "train loss:0.3040252586829482\n",
      "train loss:0.32895636046631027\n",
      "train loss:0.2607184946989589\n",
      "train loss:0.6723990467647246\n",
      "train loss:0.3988632707620393\n",
      "train loss:0.3607341098153721\n",
      "train loss:0.4568559517843702\n",
      "train loss:0.34404013853263216\n",
      "train loss:0.25156350735141725\n",
      "=== epoch:3, train acc:0.884, test acc:0.858 ===\n",
      "train loss:0.294142700297088\n",
      "train loss:0.4051073764718139\n",
      "train loss:0.5176713555722031\n",
      "train loss:0.32502519248500705\n",
      "train loss:0.3175244742776185\n",
      "train loss:0.38663537470409887\n",
      "train loss:0.3189095125853478\n",
      "train loss:0.28485367318730465\n",
      "train loss:0.27109624522366915\n",
      "train loss:0.30778399946187973\n",
      "train loss:0.29931713081654554\n",
      "train loss:0.29920166379112323\n",
      "train loss:0.24761495937677375\n",
      "train loss:0.2616885207701907\n",
      "train loss:0.23930117985512697\n",
      "train loss:0.3569520736198756\n",
      "train loss:0.29280560777642434\n",
      "train loss:0.40092455288204215\n",
      "train loss:0.24913003714918833\n",
      "train loss:0.42552125476371133\n",
      "train loss:0.2282723685364201\n",
      "train loss:0.3546587401537262\n",
      "train loss:0.33106870644582215\n",
      "train loss:0.4211821165377954\n",
      "train loss:0.3216517063902765\n",
      "train loss:0.5740480122540335\n",
      "train loss:0.28342836165548263\n",
      "train loss:0.3941154893724026\n",
      "train loss:0.2823040214784528\n",
      "train loss:0.2835260026234517\n",
      "train loss:0.36810540328936786\n",
      "train loss:0.344905519480502\n",
      "train loss:0.2135282892106223\n",
      "train loss:0.534021156617046\n",
      "train loss:0.3956619464992994\n",
      "train loss:0.2955653935156313\n",
      "train loss:0.2808556575960418\n",
      "train loss:0.19994653951074629\n",
      "train loss:0.3725747423437838\n",
      "train loss:0.40782321498792123\n",
      "train loss:0.39455130286792456\n",
      "train loss:0.261935265825098\n",
      "train loss:0.31182620687717355\n",
      "train loss:0.2676870699515813\n",
      "train loss:0.3465716965111804\n",
      "train loss:0.3750587602080476\n",
      "train loss:0.3142515608490221\n",
      "train loss:0.33610929555393376\n",
      "train loss:0.25481855208532395\n",
      "train loss:0.25419054670014496\n",
      "=== epoch:4, train acc:0.897, test acc:0.878 ===\n",
      "train loss:0.3376929698535099\n",
      "train loss:0.24842610920250746\n",
      "train loss:0.2664843308108851\n",
      "train loss:0.2666184101667978\n",
      "train loss:0.2693173066745695\n",
      "train loss:0.24133799126459166\n",
      "train loss:0.2745167977996942\n",
      "train loss:0.38397750771569045\n",
      "train loss:0.29638997761151187\n",
      "train loss:0.1787703522566029\n",
      "train loss:0.17057742424528144\n",
      "train loss:0.3255863724691059\n",
      "train loss:0.2931999831801608\n",
      "train loss:0.37162109985465797\n",
      "train loss:0.23839663974783565\n",
      "train loss:0.3607672221355681\n",
      "train loss:0.22863963589121766\n",
      "train loss:0.40098185564995653\n",
      "train loss:0.24142595107753426\n",
      "train loss:0.17521821553483805\n",
      "train loss:0.20835493115991355\n",
      "train loss:0.5255071999001208\n",
      "train loss:0.44288566991478184\n",
      "train loss:0.36411676849346397\n",
      "train loss:0.20394585556042397\n",
      "train loss:0.23548460228201196\n",
      "train loss:0.4451363718660702\n",
      "train loss:0.15210656776700168\n",
      "train loss:0.17833061886098522\n",
      "train loss:0.16712343015332248\n",
      "train loss:0.3980782536390715\n",
      "train loss:0.20939883964165612\n",
      "train loss:0.19687188775661923\n",
      "train loss:0.3571974679700268\n",
      "train loss:0.16528498520549012\n",
      "train loss:0.2191301555964134\n",
      "train loss:0.2570163499922282\n",
      "train loss:0.3210835475286812\n",
      "train loss:0.21804748022863496\n",
      "train loss:0.3071655348661302\n",
      "train loss:0.27275431376395054\n",
      "train loss:0.20094671799130862\n",
      "train loss:0.25977665905660713\n",
      "train loss:0.35659864041324474\n",
      "train loss:0.2171814518758832\n",
      "train loss:0.2341995898621756\n",
      "train loss:0.3877052345086797\n",
      "train loss:0.20752485956280664\n",
      "train loss:0.21788023829174294\n",
      "train loss:0.26680729228170214\n",
      "=== epoch:5, train acc:0.91, test acc:0.907 ===\n",
      "train loss:0.14638934997149636\n",
      "train loss:0.2049258846913575\n",
      "train loss:0.25659365345687446\n",
      "train loss:0.3561784245236413\n",
      "train loss:0.18717766896681837\n",
      "train loss:0.3367100568404063\n",
      "train loss:0.27199360716983917\n",
      "train loss:0.22156290899443803\n",
      "train loss:0.1699299174469419\n",
      "train loss:0.33127719511032827\n",
      "train loss:0.18391706074018316\n",
      "train loss:0.6204783320344673\n",
      "train loss:0.33421618924942803\n",
      "train loss:0.11521694289685558\n",
      "train loss:0.24041313336207185\n",
      "train loss:0.28255617517192017\n",
      "train loss:0.18287143078713008\n",
      "train loss:0.2375504730839642\n",
      "train loss:0.19785662755519126\n",
      "train loss:0.16279037408051408\n",
      "train loss:0.24643653320568595\n",
      "train loss:0.15662045447913114\n",
      "train loss:0.28670916886165865\n",
      "train loss:0.29033904216049866\n",
      "train loss:0.28682495627174953\n",
      "train loss:0.28376341937406147\n",
      "train loss:0.2689999346000207\n",
      "train loss:0.19905898661712054\n",
      "train loss:0.20187323487137548\n",
      "train loss:0.3458555954053299\n",
      "train loss:0.17466344336317174\n",
      "train loss:0.25653389825409123\n",
      "train loss:0.17717108806160142\n",
      "train loss:0.19042783082357173\n",
      "train loss:0.08474660659110249\n",
      "train loss:0.2321021964499952\n",
      "train loss:0.1889365825666798\n",
      "train loss:0.3111825094000959\n",
      "train loss:0.20827477646488138\n",
      "train loss:0.18324411525247408\n",
      "train loss:0.11218098048648359\n",
      "train loss:0.10360692539352744\n",
      "train loss:0.2152756777211606\n",
      "train loss:0.2651877137101115\n",
      "train loss:0.22355097088192494\n",
      "train loss:0.21800090234275032\n",
      "train loss:0.22634701793167442\n",
      "train loss:0.180841949615326\n",
      "train loss:0.1527141090129128\n",
      "train loss:0.21130548040120126\n",
      "=== epoch:6, train acc:0.929, test acc:0.9 ===\n",
      "train loss:0.227929346653579\n",
      "train loss:0.2644118726965066\n",
      "train loss:0.15835399084646026\n",
      "train loss:0.2202410753940188\n",
      "train loss:0.23644523317500027\n",
      "train loss:0.1380741129006629\n",
      "train loss:0.1535980373780814\n",
      "train loss:0.20070141158413965\n",
      "train loss:0.14090713060679344\n",
      "train loss:0.2745441364695006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3073865561122446\n",
      "train loss:0.09536844815607998\n",
      "train loss:0.13436202057529859\n",
      "train loss:0.1347814810175069\n",
      "train loss:0.17442581205240654\n",
      "train loss:0.23900018411928264\n",
      "train loss:0.30693851595412436\n",
      "train loss:0.13634430107098017\n",
      "train loss:0.07548599379590006\n",
      "train loss:0.18494640545030383\n",
      "train loss:0.12003398835350666\n",
      "train loss:0.19363866010046238\n",
      "train loss:0.14912288312423252\n",
      "train loss:0.253388459407464\n",
      "train loss:0.29614066693665364\n",
      "train loss:0.20754683081889305\n",
      "train loss:0.16372332311842044\n",
      "train loss:0.24359620590611988\n",
      "train loss:0.22156568741056526\n",
      "train loss:0.1400610291103936\n",
      "train loss:0.17367035915959478\n",
      "train loss:0.2374231481817537\n",
      "train loss:0.24462834947008397\n",
      "train loss:0.20909259766001906\n",
      "train loss:0.2894543770345303\n",
      "train loss:0.28268466481291027\n",
      "train loss:0.20693076933922513\n",
      "train loss:0.15410254354475073\n",
      "train loss:0.17539224121981636\n",
      "train loss:0.14678727617561477\n",
      "train loss:0.17922576046866304\n",
      "train loss:0.10095368377509054\n",
      "train loss:0.14008867339176886\n",
      "train loss:0.16798055829092956\n",
      "train loss:0.25609103335162525\n",
      "train loss:0.12859173405940055\n",
      "train loss:0.09791734781393233\n",
      "train loss:0.11918548483572776\n",
      "train loss:0.126584475913543\n",
      "train loss:0.07626596199632354\n",
      "=== epoch:7, train acc:0.936, test acc:0.916 ===\n",
      "train loss:0.26163724207094863\n",
      "train loss:0.14337371156632236\n",
      "train loss:0.14446163303706475\n",
      "train loss:0.21776682468942085\n",
      "train loss:0.1772729074953074\n",
      "train loss:0.28535127207924166\n",
      "train loss:0.12382072442905784\n",
      "train loss:0.2376876624666235\n",
      "train loss:0.19652049631843396\n",
      "train loss:0.17648521978627119\n",
      "train loss:0.1128094994704785\n",
      "train loss:0.1237721228469844\n",
      "train loss:0.13432169586402856\n",
      "train loss:0.17669550762091926\n",
      "train loss:0.25003735718092124\n",
      "train loss:0.15379790545289332\n",
      "train loss:0.20721394398923315\n",
      "train loss:0.10902464525184724\n",
      "train loss:0.13112282719551124\n",
      "train loss:0.10254636495540073\n",
      "train loss:0.15308979743237622\n",
      "train loss:0.12567414949068634\n",
      "train loss:0.16542335041138803\n",
      "train loss:0.18195494029785889\n",
      "train loss:0.21061656668713208\n",
      "train loss:0.09063163377195792\n",
      "train loss:0.2553099791520561\n",
      "train loss:0.1596258643939654\n",
      "train loss:0.1879583062165867\n",
      "train loss:0.24513109684703857\n",
      "train loss:0.13704226523985558\n",
      "train loss:0.13139079625138061\n",
      "train loss:0.16285146567554323\n",
      "train loss:0.18875402985756204\n",
      "train loss:0.19670937614327236\n",
      "train loss:0.13328234423536237\n",
      "train loss:0.08576307055248496\n",
      "train loss:0.13765715809669743\n",
      "train loss:0.10862022963044582\n",
      "train loss:0.1324008536636968\n",
      "train loss:0.12796500163153518\n",
      "train loss:0.17024612003673512\n",
      "train loss:0.1852733938350754\n",
      "train loss:0.2344324536628326\n",
      "train loss:0.106001571108089\n",
      "train loss:0.10510361490547482\n",
      "train loss:0.18584931022602152\n",
      "train loss:0.16811241124883694\n",
      "train loss:0.1153083680797493\n",
      "train loss:0.11183263441075318\n",
      "=== epoch:8, train acc:0.95, test acc:0.931 ===\n",
      "train loss:0.10027148986043695\n",
      "train loss:0.12621210214765685\n",
      "train loss:0.09328721648937373\n",
      "train loss:0.12343432971097826\n",
      "train loss:0.13821398368391993\n",
      "train loss:0.17714584376425652\n",
      "train loss:0.17431841116917302\n",
      "train loss:0.11417781009180814\n",
      "train loss:0.15075326619470775\n",
      "train loss:0.12257250622257183\n",
      "train loss:0.19600830004038186\n",
      "train loss:0.09364758072270239\n",
      "train loss:0.09412562254834028\n",
      "train loss:0.09506974337165619\n",
      "train loss:0.23850393976843481\n",
      "train loss:0.1693667088440365\n",
      "train loss:0.10827933140256268\n",
      "train loss:0.07478858579493108\n",
      "train loss:0.17936281117296812\n",
      "train loss:0.08747011745889967\n",
      "train loss:0.1853077782613808\n",
      "train loss:0.18356157981885243\n",
      "train loss:0.1553356831794331\n",
      "train loss:0.07794151927873738\n",
      "train loss:0.13144948111352972\n",
      "train loss:0.15064800055826238\n",
      "train loss:0.19342841802400274\n",
      "train loss:0.23417580331607266\n",
      "train loss:0.11279540173326211\n",
      "train loss:0.15056689237663756\n",
      "train loss:0.1941940060557595\n",
      "train loss:0.1821800163268132\n",
      "train loss:0.09251728981291851\n",
      "train loss:0.2262657856828627\n",
      "train loss:0.20527152976623003\n",
      "train loss:0.1362668822215014\n",
      "train loss:0.16379800881487516\n",
      "train loss:0.21195381016044532\n",
      "train loss:0.20984831517301447\n",
      "train loss:0.16901620347830593\n",
      "train loss:0.1905198443221355\n",
      "train loss:0.10492662801418877\n",
      "train loss:0.1619992595325206\n",
      "train loss:0.08301151408960614\n",
      "train loss:0.12144553603297797\n",
      "train loss:0.21753885803705322\n",
      "train loss:0.14722537096608007\n",
      "train loss:0.08371748072216245\n",
      "train loss:0.12243344055534967\n",
      "train loss:0.09724208908758575\n",
      "=== epoch:9, train acc:0.95, test acc:0.92 ===\n",
      "train loss:0.08862335206829053\n",
      "train loss:0.20724340086056753\n",
      "train loss:0.051323033185215215\n",
      "train loss:0.07529958037511594\n",
      "train loss:0.15181735801297852\n",
      "train loss:0.13293456400486212\n",
      "train loss:0.14853846185540642\n",
      "train loss:0.11712287301032283\n",
      "train loss:0.13476067654660315\n",
      "train loss:0.08658884989204355\n",
      "train loss:0.1464344681430519\n",
      "train loss:0.16050676419492654\n",
      "train loss:0.14006877303712506\n",
      "train loss:0.13822154299745656\n",
      "train loss:0.1788843196669043\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매개변수 보존\n",
    "\"\"\"\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
